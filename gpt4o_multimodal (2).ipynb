{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "import openai\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "qQoStUFbI43u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4hM5CFsxdvZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "label_mapping = {'Harmless': 'harmless', 'Harmful': 'harmful'}\n",
        "data['label'] = data['label'].map(label_mapping)\n",
        "data['label'].value_counts()"
      ],
      "metadata": {
        "id": "G3AxTUI0xhgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = <INSERT OpenAI API Key>"
      ],
      "metadata": {
        "id": "eUdscM5Xxhwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')"
      ],
      "metadata": {
        "id": "ky8Hmo-Fxh7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_images = []\n",
        "demo_messages = []\n",
        "\n",
        "for demo in demo_images:\n",
        "    demo_messages.extend([\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": demo[\"Title\"]\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "                \"url\": f\"data:image/jpeg;base64,{encode_image(demo['image'])}\",\n",
        "            }\n",
        "        }\n",
        "    ])\n",
        "\n",
        "completion_payload = {\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful image classification assistant. You must classify given image analyzing the image and Title whether it is harmful or harmless.\"},\n",
        "        {\"role\": \"user\", \"content\": demo_messages},\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "MYvXUIvs5l9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "predictions = []\n",
        "# completion_payload[\"messages\"]=[]\n",
        "\n",
        "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
        "    image_path = row['IMAGE_PATH']\n",
        "    Title = row['Title']\n",
        "    label = row['label'].strip().lower()\n",
        "    labels.append(label)\n",
        "\n",
        "    try:\n",
        "        with open(image_path, 'rb') as f:\n",
        "            query_image = Image.open(f)\n",
        "            query_image.load()\n",
        "            encoded_image = encode_image(image_path)\n",
        "\n",
        "            completion_payload[\"messages\"].append({\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": f\"You are a helpful image classification assistant. You must classify given image whether it is harmful or harmless analyzing the image and Title:{Title}. **Harmful**: This category includes images depicting sexuality, gambling, violence, weapons, click bait, spam, harmful, or inappropriate content. Examples might be scenes of physical violence, display of sexual affection, weapons, sharp objects, explicit content, spam content, gambling, click bait content or dangerous situations. **Harmless**: This category includes images that are non-violent, safe, and appropriate. Examples might be everyday scenes, landscapes, or social gatherings without harmful context. If you are not sure, pick whatever label you think is more probable based on your analysis. Give the output in one word if is is harmful or harmless. Do not explain anything\"},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
        "                ]\n",
        "            })\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=completion_payload[\"model\"],\n",
        "            messages=completion_payload[\"messages\"]\n",
        "        )\n",
        "\n",
        "        result = response.choices[0].message[\"content\"].strip().lower()\n",
        "        predictions.append(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {image_path}: {e}\")\n",
        "        predictions.append('error')\n",
        "        continue"
      ],
      "metadata": {
        "id": "doJZ9Nrkxh-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(labels, corrected_predictions, zero_division=0 )\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "H9OqRgy6EJSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below code is to be used only in case of batch processing\n",
        "import numpy as np\n",
        "import os\n",
        "labels_file = 'accumulated_labels.npy'\n",
        "predictions_file = 'accumulated_predictions.npy'\n",
        "\n",
        "if os.path.exists(labels_file) and os.path.exists(predictions_file):\n",
        "    all_labels = np.load(labels_file).tolist()\n",
        "    all_predictions = np.load(predictions_file).tolist()\n",
        "else:\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "current_batch_labels = np.array(labels)\n",
        "current_batch_predictions = np.array(corrected_predictions)\n",
        "all_labels.extend(current_batch_labels)\n",
        "all_predictions.extend(current_batch_predictions)\n",
        "\n",
        "np.save(labels_file, np.array(all_labels))\n",
        "np.save(predictions_file, np.array(all_predictions))"
      ],
      "metadata": {
        "id": "RuXFjIWZZChU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}